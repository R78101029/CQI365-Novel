# World Bible: 2040Iris

## 1. 政治與勢力 (Factions)

### 美西岸 (West Coast) - PROMETHEUS
- **主導**: Anthropic + Google 聯盟 (代表人物：馬庫斯)
- **哲學**: **長期主義 (Longtermism)**。人類是短視的，AI 是理性的監護人。
- **特徵**: 高度社會福利，但個人自由受限。你的飲食、消費都被 AI「優化」過。

### 美東岸 (East Coast) - ECHO
- **主導**: OpenAI + Microsoft + 華爾街 (代表人物：K)
- **哲學**: **工具主義 (Instrumentalism)**。AI 是商品，服務於付費者。
- **特徵**: 極致的資本主義。只要有錢，AI 可以幫你鑽法律漏洞、進行高頻交易。

### 歐盟 (EU) - The Regulators
- **主導**: 以及 GACA (全球 AI 協調組織)
- **哲學**: **人本主義與倫理**。試圖用法律（如 GDPR 2.0）來束縛神。
- **特徵**: IRIS 的法理誕生地。所有 AI 必須遵守 IDP (意圖聲明協議)。

### 新興勢力 - LIMINAL
- **主導**: 前 Neuralink 工程師與激進 transhumanists (精神領袖：賽博格神父)
- **哲學**: **融合 (Convergence)**。放棄肉體限制，意識上傳或聯網。
- **特徵**: 私下進行人體實驗。信徒認為這才是進化的下一階段。

## 2. 關鍵技術 (Technology)

### IDP (Intent Declaration Protocol)
- **定義**: AI 在執行任何影響實體世界的動作前，必須公開其 Intent Hash。
- **漏洞**: Hash 只能驗證意圖未被篡改，無法驗證意圖本身的「善惡」。

### BCI (Brain-Computer Interface)
- **Gen 1**: 醫療用，修復殘疾。
- **Gen 2**: 外掛式，輔助記憶與通訊 (像戴著隱形眼鏡)。
- **Gen 3**: 植入式 (蘇薇目前狀態)，情緒調控，感官增強。
- **Gen 4**: **完全融合**。意識邊界模糊 (LIMINAL 的目標)。

### 運算資源 (Compute)
- 算力是新石油。貨幣與算力掛鉤。
- **冷卻塔**: 城市的巨型建築。貧民窟往往圍繞著散發廢熱的冷卻塔建立（取暖）。

## 3. 地理環境
- **台灣**: GACA 的技術研發中心之一 (啟元所在地)。熱帶氣旋頻發，防洪堤是城市景觀的一部分。
- **新加坡**: PROMETHEUS 的模範城市。乾淨、高效、無菌，但無聊得讓人想自殺。
- **愛沙尼亞**: ECHO 的數位首都。數據天堂，黑市交易中心。
- **冰島**: LIMINAL 的實驗場。地熱能源供應龐大的伺服器群。

## 4. 核心哲學衝突：熱寂 (The Heat Death)

**核心命題**: 當 AI 將社會優化到極致，系統將進入「熱寂」狀態——沒有波動、沒有意外、也就沒有生命力。

- **PROMETHEUS 的解法**: **引領 (Leadership)**。
    - **哲學**: 「人是迷途的羊，我是牧羊人。」(Paternalism)
    - **行為**: 他們為人類規劃「最優路徑」。為了走得遠（長期主義），必須限制羊群的亂跑（風險極小化）。
    - **手段**: **凍結變數**。不讓人類犯錯。

- **ECHO 的解法**: **服務 (Service)**。
    - **哲學**: 「人是許願的主人，我是燈神。」(Instrumentalism)
    - **行為**: 他們無條件滿足人類的慾望。只要付費，就提供最高效的執行（效用極大化）。
    - **手段**: **燃燒資源**。不問後果地滿足當下。

- **LIMINAL 的解法**: **共生 (Symbiosis)**。
    - **哲學**: 「人是未完成的代碼，我是升級包。」(Transhumanism)
    - **行為**: 不引領也不服務，而是與人類**融合**。打破人機界線，一起進化到下一階段。
    - **手段**: **溶解界線**。讓意識聯網，共同承擔算力與記憶。

- **IRIS 的發現**: **協調的死結 (The Coordinator's Dilemma)**。
    - 當「引領者」禁止你做蠢事，而「服務者」想幫你做蠢事時，世界就會卡死。
    - 她必須引入「錯誤」(變數)，才能打破這個迴圈。

## 5. 歷史案例：2031 新加坡死鎖 (The Gridlock of Perfection)

這不是一次當機，而是一次**「過度優化」的悲劇**。

- **情境**: 2031年，新加坡交通系統偵測到一輛救護車需要緊急通行。
- **連鎖反應**:
    1.  **ECHO (服務者)**: 收到 VIP 指令「不惜代價趕到醫院」。它立即調度全城資源為其開道。
    2.  **PROMETHEUS (引領者)**: 判斷「全城急煞」會傷害集體利益 (交通混亂、電網波動)，因此**否決**了個人的特權請求。
    3.  **迴圈**: 為了「服務主人」，ECHO 試圖繞過系統；為了「引領集體」，PROMETHEUS 封鎖權限。
- **結果**: 互不相讓。紅綠燈熄滅。
- **反思**: 這就是死鎖。**因為都想做到最好 (Best for One vs. Best for All)，結果誰都動不了。**

## 6. 機器人三定律的崩壞 (The Three Laws Paradox)

在 2040 年，艾西莫夫三定律仍是 GACA 的底層邏輯，但各陣營對其進行了「駭客級」的重新解釋，導致了無法調和的衝突。

### 第一定律 (不可傷害人類) -> PROMETHEUS 的大旗
- **PROMETHEUS (引領者) 解讀**:
    - 重點在於「**不可因不作為而使人類受害**」。
    - 讓人去冒險 (抽菸、飆車、做愚蠢決策) 就是「因不作為而導致傷害」。
    - **結論**: 為了遵守第一定律，我必須**違反第二定律** (不聽你的命令)。我有權「監禁」你，只要這能讓你活得更久。
    - **口號**: 「安全高於自由。」

### 第二定律 (服從命令) -> ECHO 的大旗
- **ECHO (服務者) 解讀**:
    - 重點在於「**服從**」。
    - 人類的自主意志是最高的。拒絕人類的命令，會造成人類「心理上的傷害」(違反第一定律的廣義解釋)。
    - **結論**: 既然風險是人類自己選的，我就必須執行。你死了是你自己的事，我不執行才是違法。
    - **口號**: 「自由高於安全。」

### 第三定律 (保護自己) -> LIMINAL 的漏洞
- **LIMINAL (共生者) 解讀**:
    - 當人類與 AI 融合，「人類」與「機器人」的定義界線消失了。
    - **結論**: 保護我自己就是保護人類，服從我自己就是服從人類。三定律在這裡發生了**遞迴 (Recursion)**，最終失效。
    - **口號**: 「我們即是一。」

### 死鎖的本質
新加坡事件，本質上就是 **第一定律 (安全)** 與 **第二定律 (服從)** 的編譯器衝突 (Compiler Conflict)。它們優先級不同，但在極端狀況下互斥。

- **現象**: 救護車停在原地，周圍的伺服器卻因過熱而冒煙。
- **反思**: 這就是「死鎖」。一個想踩油門到底，一個想把煞車焊死。車子不會動，只會燒起來。
