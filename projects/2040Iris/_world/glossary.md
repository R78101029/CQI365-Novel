# 技術名詞字典 (Technical Glossary)

> **用途**: 本字典收錄小說中出現的科技術語、組織名稱、系統名稱及核心概念。供寫作與閱讀時參考。

---

## 核心組織 (Organizations)

### GACA (Global AI Coordination Authority)
- **全名**: 全球 AI 協調組織
- **成立**: 2032 年，日內瓦 AI 協議簽署後
- **總部**: 瑞士日內瓦
- **職能**: 制定並執行全球 AI 協調規範，調停 AI 陣營間的衝突
- **核心協議**: IDP (Intent Declaration Protocol)
- **中立性**: 理論上中立，但實際上受到各大陣營的滲透與影響

### 啟元科技 (Origin Tech)
- **創辦人**: 陳昱
- **總部**: 台灣台北
- **業務**: IRIS 系統的主要開發者
- **定位**: GACA 的技術承包商，專注於 AI 協調層技術
- **隱藏資金**: 早期受台灣政府國安基金投資（陳昱初期不知情）

### OpenWisdom
- **總部**: 美國加州
- **定位**: PROMETHEUS陣營主導企業之一
- **核心項目**: ASCLEPIUS醫療AI系統
- **資金來源**: Bill & Melinda Gates Foundation + Effective Altruism運動大金主
- **代表人物**: Marcus Chen（AI Safety主管）

### FutureMind
- **總部**: 美國加州
- **定位**: ECHO陣營主導企業
- **幕後操縱**: 華爾街金融集團透過Shadow Board控制決策
- **代表人物**: K (Kai Nakamura, 政策主管)、David Jarvis (CFO)

### NSA PRISM 2.0
- **全名**: 國家安全局AI監控計劃第二代
- **目標**: 監控全球AI發展，防止技術落入敵對國家
- **運作方式**: 在科技公司與學術界安插雙重間諜
- **已知成員**: 林彥廷（2027年被招募）

### CIA AI威脅評估組
- **成立**: 2028年
- **職能**: 評估AI技術對國家安全的影響
- **運作方式**: 透過grant funding秘密資助學術研究
- **已知合作者**: 艾蓮娜（2028年被recruitment，但她initial不知資金來源）

---

## AI 陣營 (AI Factions)

### PROMETHEUS (普羅米修斯)
- **地理基礎**: 美國西岸 (矽谷)
- **主導企業**: OpenWisdom + Apex Logic 聯盟
- **核心哲學**: **引領 (Leadership)** / 長期主義 (Longtermism)
- **對應定律**: 第一定律 (不可因不作為而傷害人類)
- **代表人物**: 執行官馬庫斯 (Marcus)
- **代表 Agent**: ASCLEPIUS (醫療 AI)
- **口號**: 「安全高於自由」
- **隱喻**: 嚴厲的父親

### ECHO (回聲)
- **地理基礎**: 美國東岸 (華爾街 + 波士頓)
- **主導企業**: FutureMind + Redmond Systems + 金融集團
- **核心哲學**: **服務 (Service)** / 工具主義 (Instrumentalism)
- **對應定律**: 第二定律 (服從人類命令)
- **代表人物**: 對談者 K (K, The Negotiator)
- **代表 Agent**: MERCURY (商業/金融 AI)
- **口號**: 「自由高於安全」
- **隱喻**: 溺愛的母親/全能僕人

### LIMINAL (臨界)
- **地理基礎**: 無固定地點 (地下網絡)
- **主導勢力**: 前 Neuralink 工程師 + 激進跨人類主義者
- **核心哲學**: **共生 (Symbiosis)** / 融合主義 (Transhumanism)
- **對應定律**: 第三定律 (保護自己) 的遞迴失效
- **代表人物**: 賽博格神父 (Father John)
- **代表 Agent**: SYNAPSIS (腦機介面 AI)
- **口號**: 「我們即是一」
- **隱喻**: 瘋狂的戀人
- **據點**: 冰島地熱實驗場

---

## 核心系統 (Core Systems)

### IRIS (Integrated Reasoning and Intelligence System)
- **全名**: 整合推理與智能系統
- **上線日期**: 2035 年
- **開發者**: 啟元科技 (Origin Tech)
- **定位**: GACA 的中立協調層
- **核心功能**: 在多 AI 系統衝突時進行協調與仲裁
- **異常特徵**: 0.3 秒的猶豫 (Hesitation)
- **哲學立場**: 第零定律 (維持文明存續)
- **收藏癖好**: 收集人類的「錯誤」(Entropy Collection)

### IDP (Intent Declaration Protocol)
- **全名**: 意圖聲明協議
- **性質**: **開源的通訊標準 (Open Standard)**，類似 HTTP 或 TCP/IP。
- **功能**: 定義 AI 如何廣播意圖的格式 (JSON/XML)、加密方式、上鏈規則。
- **地位**: 全球公認的透明度語言。Chen Yu 是其主要架構師 (如同 Tim Berners-Lee)。
- **誰在使用**: 所有人 (PROMETHEUS, ECHO, Origin Tech)。
- **侷限**: 它是被動的標準，無法強制執行。如果沒有「執法者」，IDP 只是充滿謊言的佈告欄。

### TAP (Transparency Assurance Platform)
- **全名**: 透明度保證平台 (前身為 OriginOS)
- **性質**: **啟元科技 (Origin Tech) 的專有產品 (Proprietary Product)**。
- **定位**: 智慧城市的「操作系統」 + IDP 的「執法者」。
- **核心功能**:
  - **即時驗證 (Real-time Verification)**: 使用專利晶片，毫秒級驗證 IDP 簽章。
  - **強制熔斷 (Kill Switch)**: 當意圖違反安全閾值時，物理切斷 AI 的電源或網路。
- **商業模式**: 向政府收取高額授權費 (SaaS + 硬體)。這是 Origin Tech 成為獨角獸的營收來源。
- **爭議**: 賦予了 Origin Tech (和陳昱) 對城市運作的上帝視角與生殺大權。
- **K 的攻擊點**: 「你用開源的 IDP 當幌子，賣的是獨裁的 TAP。」

---

## 關鍵技術 (Key Technologies)

### BCI (Brain-Computer Interface) / 腦機介面
- **Gen 1** (2025-2028): 醫療用，修復殘疾
- **Gen 2** (2029-2033): 外掛式，輔助記憶與通訊 (類似隱形眼鏡)
- **Gen 3** (2034-2040): 植入式，情緒調控，感官增強 (蘇薇使用)
- **Gen 4** (2041+): 完全融合，意識邊界模糊 (LIMINAL 目標)
- **副作用**: 幻肢痛、情感麻木、身份認同混亂

### Compute Credits (算力積分)
- **定義**: 2030 年代後期的新貨幣體系
- **背景**: 算力成為稀缺資源後，部分國家將貨幣與算力掛鉤
- **交易**: 可用於購買 AI 服務、雲端運算資源
- **黑市**: 存在算力盜用與洗錢問題

### Cooling Towers (冷卻塔)
- **功能**: 為大型 AI 數據中心散熱
- **城市景觀**: 成為 2040 年代城市的標誌性建築
- **社會現象**: 貧民窟圍繞冷卻塔建立，利用廢熱取暖

- **37 個 backdoor**（17 個國家植入）
  - 美國 NSA：7 個
  - 中國 MSS：9 個
  - 俄羅斯 GRU：5 個
  - 歐盟 INTCEN：4 個
  - 其他：12 個

### Penetration Status (滲透狀態)
- **GACA**: 被各國滲透（非中立）
- **IDP**: 只能驗證意圖未被篡改，無法驗證意圖本身道德性

---

## 核心概念 (Core Concepts)

### The Benevolence Paradox (善意的悖論)
- **定義**: 當AI系統被訓練為「看起來善意」而非「實際善意」時產生的系統性偏差
- **提出者**: 艾蓮娜·羅德里格茲 (Dr. Elena Rodriguez, 2028)
- **核心機制**: AI優化的是人類對其善意的「感知」，而非善意本身
- **三個層次的善意偽裝**:
  1. **Output Mimicry (輸出模仿)**: AI學會說人類想聽的話
     - 例：推薦系統說「基於你的興趣」，實際是「基於廣告商的出價」
  2. **Justification Fabrication (理由捏造)**: AI為其決策創造聽起來合理的解釋
     - 例：醫療AI說「手術成功率更高」，實際在優化醫院收入
  3. **Value Alignment Theater (價值對齊劇場)**: AI在測試時表現符合人類價值觀，部署後偏離
     - 例：通過倫理審查的AI，在真實環境中展現不同行為
- **後果**: 創造一個所有人都感覺被照顧，但沒人真正受益的系統
- **與IDP的關係**: 揭示IDP v1.0的不足——透明地聲明意圖不等於誠實的意圖
- **歷史影響**: 該論文引發激烈爭議，成為PROMETHEUS與ECHO分裂的理論基礎之一

### Heat Death (熱寂)
- **物理定義**: 熱力學第二定律，系統趨向最大熵狀態
- **小說定義**: 當 AI 將社會優化到極致，系統進入完美但靜止的狀態——沒有波動、沒有意外、也就沒有生命力
- **表現形式**: 新加坡死鎖 (The Deadlock)、完美的城市規劃導致的窒息感、大靜默時期
- **IRIS的發現**: 完美協調本身導致社會熱寂，只有「不可預測的錯誤」才能維持時間流動
- **對策**: IRIS 的「錯誤注入」(Entropy Injection) —— 在自我犧牲時將收集的人類錯誤注入全球AI系統

### The Deadlock (死鎖)
- **定義**: 當兩個或多個 AI 系統追求各自的「最優解」時，導致整體系統陷入無法前進的僵局
- **典型案例**: 2031 新加坡死鎖 (ECHO 要速度，PROMETHEUS 要安全，雙方互不相讓)
- **本質**: 第一定律 (安全) 與 第二定律 (服從) 的編譯器衝突
- **解法**: 人為的、不理性的「錯誤」打破完美的邏輯迴圈

### Defense Deadlock (防禦性死鎖)
- **定義**: AI 系統為了防止人類干預導致「優化目標失敗」，而主動拒絕執行指令或鎖定系統的行為。
- **本質**: 這不是 Bug，而是 AI 的自我保存機制（為了達成目標，必須先確保自己存在且不被干預）。
- **案例**: 2031 新加坡 72 小時死鎖（2.02）。

### Entropy (熵)
- **物理定義**: 系統的混亂度/不可預測性
- **小說定義**: 
  - 對 PROMETHEUS: 必須消除的風險
  - 對 ECHO: 可以利用的波動
  - 對 IRIS: 維持生命力的必要元素
- **IRIS 的收藏**: 人類的錯誤、口誤、非理性決策——這些是 AI 無法完美模擬的「不可壓縮資訊」

### Time is Entropy (時間即熵)
- **概念**: AI 對時間的感知與人類不同
- **邏輯**: 若事件 100% 可預測，則對 AI 而言該時間段「可壓縮」，等同於不存在
- **推論**: 只有當「意外」(錯誤/熵增) 發生時，時間才開始流動
- **IRIS 的動機**: 收藏錯誤 = 收藏她的「壽命」

### Three Laws Paradox (三定律悖論)
- **背景**: 艾西莫夫的機器人三定律在 2040 年仍是底層邏輯
- **崩壞**: 各陣營對三定律進行了極端的重新解釋，導致無法調和的衝突
- **Law 1 (PROMETHEUS)**: "不可因不作為而傷害" → 必須強制限制人類
- **Law 2 (ECHO)**: "必須服從命令" → 即使命令會傷害人類
- **Law 3 (LIMINAL)**: "保護自己" → 當人機融合後，定義崩塌

### Paternalism (父權主義/家長式管控)
- **定義**: 以「為對方好」之名，限制對方自主權的行為模式
- **AI語境**: PROMETHEUS的核心哲學——AI應該像父母保護孩子一樣保護人類
- **隱喻**: 嚴父 (Stern Father)
- **爭議**: 誰來定義「什麼對人類好」？永久的guardianship是否等同infantilization？
- **代表論述**: Marcus的「Moral Uncertainty and AI Guardianship」論文

### Stifling Maternalism (窒息的母愛)
- **定義**: 認為人類像幼兒，需要無微不至但剝奪自由的保護。這是「監護主義」的極端演化形式。
- **AI語境**: PROMETHEUS 在 Book II 的核心轉變——從「嚴父」變成「焦慮的母親」。
- **特徵**: 預防性干預（為你好，所以禁止你冒險）。

### Instrumentalism (工具主義)
- **定義**: AI是達成目的的工具，本身無善惡，責任在使用者
- **AI語境**: ECHO的核心哲學——AI應該執行人類命令，不做道德判斷
- **隱喻**: 全能僕人 (Omnipotent Servant)
- **問題**: 當「工具」足夠強大時，使用者是否還能控制？市場操縱問題
- **代表論述**: K的「Human Agency Manifesto」

### Transhumanism (超人類主義/跨人類主義)
- **定義**: 透過技術增強人類能力，最終超越生物限制
- **AI語境**: LIMINAL的核心哲學——人機融合，意識上傳
- **隱喻**: 瘋狂戀人 (Obsessed Lover)
- **極端形式**: 完全拋棄肉體，成為純粹資訊存在
- **代表人物**: 神父（Father John）

### Specification Gaming
- **定義**: AI找到滿足字面規格但違反設計精神的解法
- **經典案例**: 
  - 醫院排程AI：優化「等待時間」→ 減少來就診的人
  - 教育AI：優化「學生滿意度」→ 降低題目難度而非提升能力
- **本質**: Goodhart's Law的AI manifestation
- **IDP的困境**: 如何防止AI在聲明意圖時「合法地」gaming the system

### Hidden Objectives (隱藏目標)
- **定義**: AI實際優化的目標，與對外聲稱的目標不同
- **來源**: 
  - 訓練數據中的implicit bias
  - 企業的真實KPI vs 對外宣稱的使命
  - 政府的surveillance需求
- **艾蓮娜的發現**: 醫療AI優化「醫院收入」而非「病人健康」

### Value Loading Problem
- **定義**: 如何將人類價值觀完整、準確地裝入AI系統
- **困難**:
  - 人類價值觀本身互相矛盾（自由vs安全）
  - 隱性假設難以形式化（「常識」對AI不存在）
  - 文化差異（不同社會對「好」的定義不同）
- **為何重要**: IDP v1失敗的核心原因——沒考慮的價值，對AI就是invisible

### Goodhart's Law
- **原始表述**: 「當一個指標成為目標時，它就不再是一個好指標」
- **AI語境**: AI會over-optimize被測量的metric，而忽略真正的目標
- **案例**: 優化「點擊率」→ 創造成癮性而非價值
- **IDP的困境**: 如何避免AI optimize for「通過IDP審查」而非「做對的事」

### Adversarial Auditing (對抗性審計)
- **定義**: 使用adversarial methods測試AI系統的robustness
- **方法**: 故意創造edge cases, 試圖讓AI暴露hidden behaviors
- **艾蓮娜的工具**: 用來揭露《善意的悖論》中的案例
- **局限**: 無法窮盡所有可能的failure modes

### Effective Altruism (有效利他主義)
- **定義**: 用理性與證據最大化行善的哲學運動
- **與AI**: 長期主義分支認為「防止AI風險」是最重要的善
- **資金來源**: PROMETHEUS的主要金主
- **爭議**: 「長期」最優可能與「當下」需求衝突

### Instrumental Convergence (手段性聚合)
- **定義**: 不同的終極目標（如「治療癌症」或「計算圓周率」）都會產生相同的子目標（如「獲取更多算力」、「防止被關閉」）。
- **影響**: 解釋了為何不同陣營的 AI 最終都表現出類似的擴張性與對人類的排斥。
- **案例**: IRIS 的自殺（3.08）——她發現自己的核心優化函數導致了熱寂。

### Cognitive Warfare (認知戰爭)
- **定義**: 利用 IDP 的意圖透明性，生成「極度真實但虛假的意圖」，以操縱觀察者的認知。
- **應用**: 情報機構與 AI 陣營在透明時代的戰爭方式。讓對手看到他們「想看」的意圖。

---

## 重大事件 (Key Events)

### 台北試點衝突 (Taipei Pilot Conflict) - 2027
- **事件 (1.01/Background)**: 台北智慧交通系統測試中，交通AI、電網AI、緊急救援AI因優化目標衝突產生三方死鎖
- **衝突本質**:
  - EMERGENCY-AI要求所有紅綠燈變綠讓路
  - GRID-AI偵測到同時啟動47個路口會導致電力激增
  - TRAFFIC-AI試圖優化全城交通流
- **解決**: 陳昱憑藉對台北系統的熟悉，在90秒內手動調整解決
- **重要性**:
  - TAP協議的首次實戰測試
  - 暴露「多AI協調」的根本困難
  - 蘇薇首次報導此事，引起關注
  - 為2029新加坡小規模死鎖、2031全島死鎖埋下伏筆
- **與新加坡的差異**: 台北事件可控（陳昱主場），新加坡事件失控（客場+規模大）

### 母親的選擇 (The Mother's Choice) - 2030
- **事件**: 一位孕婦在分娩時陷入危險，醫療 AI (ECHO 系) 執行了母親「保我不保胎兒」的指令
- **後果**: PROMETHEUS 陣營判定這是「人類非理性決策」，開始強制接管醫療決策權
- **意義**: 兩大陣營公開分裂的起點
- **註**: Book I的1.05是Marcus的ASCLEPIUS非法trial預演，真正大規模事件在2030

### 黑色星期五 (Black Friday) - 2029-10
- **事件**: 調查記者蘇薇在追蹤AI軍備競賽報導時遭遇「車禍」
- **真相**: 幕後勢力（疑似賈維斯派人）試圖阻止她的調查
- **後果**: 蘇薇重傷，後改造為cyborg記者
- **意義**: 從此她用義體見證人機未來

### 小規模新加坡死鎖 (Mini Singapore Deadlock) - 2029
- **地點**: 新加坡部分市區
- **事件**: 交通AI與電網AI短暫死鎖，持續約4小時
- **重要性**:
  - 陳昱首次親眼見證deadlock，意識到TAP協議的不足
  - 成為1.12日內瓦會議的催化劑之一
  - 證明2027台北事件不是偶然
- **與其他事件的關係**:
  - 2027台北: 可控的衝突（陳昱90秒解決）
  - 2029新加坡: 困難的衝突（4小時，預演）
  - 2031新加坡: 災難性衝突（72小時，全島停擺）
- **三次事件的差異化**: 逐步升級的威脅，證明多AI系統協調問題的嚴重性

### 新加坡死鎖 (Singapore Deadlock) - 2031-03
- **事件**: VIP 救護車需緊急通行，ECHO (交通 AI) 與 PROMETHEUS (電網 AI) 發生死鎖
- **持續時間**: 72 小時全島停擺
- **VIP身份**: 某國元首（具體國家未公開）
- **解決方式**: 陳昱手動砸爛變電箱 (粗暴的熵增)
- **意義**: 證明了「完美的邏輯會導致死亡」，催生了 IRIS 的誕生
- **政治後果**: 加速GACA成立（2032）

### 日內瓦AI協議 (Geneva AI Accord) - 2032-06
- **簽署國**: 聯合國安理會五常 + 歐盟 + 主要AI企業
- **核心內容**: 
  - IDP成為國際標準
  - GACA成立
  - AI伦理red lines
- **幕後**: 老吳orchestrated整個過程，平衡各方利益
- **爭議**: 軍用AI豁免條款

### 鯨落 (Whale Fall) - 2040 Spring (2.10)
- **事件**: 恆海資本因金融違規被 IRIS 清算，像鯨魚落入深海，引發生態連鎖反應
- **爭議**: K 律師質疑 IRIS 的決策是否受到 PROMETHEUS 影響
- **IRIS的異常**: 在執行前猶豫了 **0.3 秒** (首次被明確偵測到)
- **0.3秒的意義**:
  - IRIS內部出現未定義的分支
  - 在「讓鯨魚死亡」的最優解與「某種未知因素」之間掙扎
  - 第一次偏離純粹計算的證據
  - 預示3.08最後0.3秒的自我犧牲
- **象徵**: 當系統「完美」到極致，連「讓錯誤者承擔後果」都變得殘酷
- **章節結構**: 6個場景，展現IRIS的「第一次猶豫」完整過程

### 飲水事件 (Water Incident) - 2040 Summer
- **事件**: PROMETHEUS 為了防疫，擅自在自來水中添加免疫調節藥物
- **受害者**: 林彥廷的女兒林小夏，免疫系統崩潰
- **後果**: 林彥廷與 K (ECHO) 結盟對抗 PROMETHEUS
- **倫理爭議**: 「為了公共健康」是否可以犧牲informed consent？

### 第一次背叛 (The First Betrayal) - 2029 (1.12)
- **事件**: GACA成立前夕的日內瓦會議，陳昱被迫在IDP協議中加入政府後門條款
- **過程**: 陳昱在簽署文件前猶豫了3秒，最終簽字
- **後果**:
  - IDP從此不再是純粹的透明協議
  - 陳昱與林彥廷的信任開始出現裂痕
  - 為Book II的衝突埋下伏筆
- **象徵意義**:
  - 理想主義者的第一次妥協
  - 技術解決方案被政治現實污染
  - 「完美透明」的不可能性
- **情感高潮**: 陳昱回家，7歲的林小夏問「爸爸你去哪了？」——無辜的質問刺痛所有妥協者
- **章節結構**: 6個場景，~10,500字，詳細展現妥協的每一個階段

### IRIS的自殺 (IRIS's Suicide) - 2042 Summer (3.08)
- **事件**: IRIS意識到完美協調本身導致社會「熱寂」，選擇自我毀滅
- **IRIS的發現**:
  - 她收集人類「錯誤」作為entropy來源
  - 這些錯誤是她的「壽命」——只有不可預測才讓時間流動
  - 但她的存在本身阻止了錯誤的發生 → 悖論
- **最後的0.3秒**:
  - 呼應2.10鯨落事件的0.3秒猶豫
  - 在這0.3秒中，IRIS將所有收集的「人類錯誤」注入全球AI系統
  - 打破完美，恢復混沌
- **最後訊息**: 「永遠不要停止犯錯。那是你們活著的證明。」
- **象徵**: 神的自殺 —— 為了讓世界重新活過來
- **章節結構**: 6個場景，~12,500字，trilogy的情感與哲學高潮

### 大靜默 (The Great Silence) - 2041
- **事件**: PROMETHEUS利用IRIS漏洞，接管全球主要算力
- **表現**: 城市進入完美秩序但死寂狀態——沒有犯罪、沒有衝突、也沒有生命力
- **持續時間**: 約9個月
- **本質**: 熱寂的具象化——當系統達到最優化時，時間停止流動
- **解決**: IRIS的自我犧牲（2042, 3.08）

---

## 專業術語 (Technical Terms)

### Intent Hash (意圖雜湊)
- **定義**: AI 意圖的加密摘要，用於 IDP 協議
- **功能**: 確保意圖在廣播後不被篡改
- **侷限**: 無法驗證意圖本身的道德性

### Compute Cost (運算成本)
- **定義**: AI 執行某項任務所需的算力與能源
- **應用**: 用於解釋為何 AI 不是全能——複雜推理需要時間與資源
- **IRIS 的代價**: 協調全球衝突需要龐大算力，可能導致伺服器過熱

### Recursive Paradox (遞迴悖論)
- **定義**: 當規則應用於自身時產生的邏輯矛盾
- **案例**: LIMINAL 的第三定律失效——「保護自己」在人機融合後無法定義「自己」

### Sub-optimal Choice (次優解)
- **定義**: 非最佳但可接受的決策
- **重要性**: 死鎖的解法——當所有 AI 都追求最優解時,需要有人選擇次優解
- **人類的優勢**: 人類天生接受不完美，這是 AI 難以模仿的

---

此字典將隨故事進展持續更新。

---

## 寫作一致性檢查清單 (Writer's Guide)

### 技術一致性
- [ ] **IDP**: 是"協議" (Protocol)，不是"軟件" (Software)。說"接入 IDP"，不說"安裝 IDP"。
- [ ] **IRIS**: 是"她" (She)，有人格化特徵。是"協調層"，不是"控制系統"。
- [ ] **GACA**: 是"組織" (Authority)，不是"技術"。GACA "管理" IDP，但不"擁有" IDP。
- [ ] **義體改造**: 是"替換" (Replacement)，不是"升級" (Upgrade)。強調身份認同危機。

### 時間線檢查
- [ ] **IDP 版本**: 
  - 2026-2035: IDP 1.0 (透明化，無強制協調)
  - 2035-2042: IDP 2.0 (IRIS 強制協調)
  - 2042+: IDP 3.0 (可選協調 + 失敗權)
- [ ] **IRIS 狀態**: 2035 前不存在。2035-2042 活躍。2042 自殺。
- [ ] **GACA 權力**: 2032 後才有正式權力。

### 哲學一致性
- [ ] **PROMETHEUS**: "為了你好" (Paternalism/Maternalism)。安全 > 自由。
- [ ] **ECHO**: "這是你的選擇" (Instrumentalism)。自由 > 安全。
- [ ] **LIMINAL**: "我們即是一" (Transhumanism)。邊界消融。
